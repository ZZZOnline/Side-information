# general
gpu_id: 0
use_gpu: True
seed: 212
state: INFO
reproducibility: True
data_path: 'dataset/'
checkpoint_dir: 'saved'
show_progress: True
save_dataset: False
save_dataloaders: False

# dataset
load_col:
    inter: [user_id, item_id, timestamp, behavior]
    item: ['item_id', 'categories', 'brand_id']
    user: ['user_id', 'age', 'gender']
MAX_ITEM_LIST_LENGTH: 50
USER_ID_FIELD: user_id
ITEM_ID_FIELD: item_id
RATING_FIELD: rating
TIME_FIELD: timestamp

# Filtering
val_interval: ~
filter_inter_by_user_or_item: True
user_inter_num_interval: "[5,inf)"
item_inter_num_interval: "[5,inf)"

# Model
mask_ratio: 0.2
n_layers: 2
n_heads: 2
hidden_size: 128
embedding_size: 128
attribute_hidden_size: [128]
inner_size: 128
hidden_dropout_prob: 0.3
attn_dropout_prob: 0.3
hidden_act: 'gelu'
layer_norm_eps: 1e-12
initializer_range: 0.02
selected_features: ['categories']
pooling_mode: 'sum'
pooling_type: 'average'
loss_type: 'CE'
weight_sharing: 'not'
fusion_type: 'sum'
lamdas: [1, 1]
attribute_predictor: 'linear'
reg_weight: [0.0005, 0.0005]
gamma: 0.8
beam_size: 50
# training settings
epochs: 50
# train_batch_size: 2048
train_batch_size: 512
learner: adam
learning_rate: 0.0001
eval_step: 2
stopping_step: 10
clip_grad_norm: ~
weight_decay: 0.0
neg_sampling:

# evaluation settings
eval_args:
  split: { 'LS': 'valid_and_test' }
  group_by: user
  order: TO
  mode: full

repeatable: True
metrics: ["Recall","NDCG"]
topk: [5,10,20, 50]
valid_metric: Recall@20
valid_metric_bigger: True
eval_batch_size: 64
loss_decimal_place: 4
metric_decimal_place: 4